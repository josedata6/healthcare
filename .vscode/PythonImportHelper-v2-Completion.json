[
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "psycopg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psycopg",
        "description": "psycopg",
        "detail": "psycopg",
        "documentation": {}
    },
    {
        "label": "create_engine",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "open_text",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def open_text(path):\n    if path.lower().endswith(\".gz\"):\n        return gzip.open(path, \"rt\", errors=\"replace\", encoding=\"utf-8\")\n    return open(path, \"r\", errors=\"replace\", encoding=\"utf-8\")\ndef first_lines(path, n=3):\n    with open_text(path) as f:\n        return [f.readline() for _ in range(n)]\ndef normalize(s: str) -> str:\n    if not isinstance(s, str):\n        s = str(s)",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "first_lines",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def first_lines(path, n=3):\n    with open_text(path) as f:\n        return [f.readline() for _ in range(n)]\ndef normalize(s: str) -> str:\n    if not isinstance(s, str):\n        s = str(s)\n    # unify whitespace and separators for matching\n    s = s.replace(\"\\u00A0\", \" \")       # NBSP -> space\n    s = s.replace(\"\\u2007\", \" \")       # figure space\n    s = s.replace(\"\\u202F\", \" \")       # narrow NBSP",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def normalize(s: str) -> str:\n    if not isinstance(s, str):\n        s = str(s)\n    # unify whitespace and separators for matching\n    s = s.replace(\"\\u00A0\", \" \")       # NBSP -> space\n    s = s.replace(\"\\u2007\", \" \")       # figure space\n    s = s.replace(\"\\u202F\", \" \")       # narrow NBSP\n    s = re.sub(r\"\\s+\", \" \", s)\n    s = s.strip().lower()\n    return s",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "score_header",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def score_header(raw_header_line: str) -> int:\n    \"\"\"Give a higher score if header looks like a charge file header, not admin.\"\"\"\n    h = normalize(raw_header_line)\n    score = 0\n    # reward pricing tokens\n    for tok in EXPECTED_TOKENS:\n        if tok in h:\n            score += 2\n    # penalize if it's clearly admin-y\n    for tok in ADMIN_HINTS:",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "read_csv_pass",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def read_csv_pass(path, skiprows=0):\n    \"\"\"Read with pandas in a tolerant way (autodetect delimiter).\"\"\"\n    return pd.read_csv(\n        open_text(path),\n        dtype=str,\n        sep=None, engine=\"python\",  # autodetect delimiter\n        quotechar='\"',\n        on_bad_lines=\"skip\",\n        skipinitialspace=True,\n        keep_default_na=False,",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "clean_one_file",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def clean_one_file(src_path, out_path):\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n    # Pass A: assume first row is header\n    lines = first_lines(src_path, n=3)\n    line1 = lines[0] if lines else \"\"\n    score_A = score_header(line1)\n    # Pass B: strip the first 2 rows (common WA admin header + attestation)\n    line3 = lines[2] if len(lines) >= 3 else \"\"\n    score_B = score_header(line3)\n    # If Pass B header looks more like a pricing header, use Pass B",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "def main():\n    files = []\n    for pat in (\"*.csv\", \"*.csv.gz\"):\n        files.extend(glob.glob(os.path.join(IN_DIR, pat)))\n    if not files:\n        print(f\"⚠️  No files found in {IN_DIR}\")\n        return\n    print(f\"Found {len(files)} file(s). Cleaning into {OUT_DIR} …\")\n    for src in sorted(files):\n        rel = os.path.relpath(src, IN_DIR)",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "OUT_DIR",
        "kind": 5,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "OUT_DIR = \"/Users/jdd48774/Downloads/out-tall\" # cleaned folder\nFORCE_GZIP = True  # True -> write .csv.gz\n# Pricing/structure headers we expect in a REAL header row\nEXPECTED_TOKENS = {\n    \"description\", \"code|\", \"code|1\", \"code|1|type\", \"code|2\", \"code|2|type\",\n    \"standard_charge\", \"standard_charge|gross\", \"standard_charge|discounted_cash\",\n    \"standard_charge|negotiated_dollar\", \"standard_charge|negotiated_percentage\",\n    \"standard_charge|min\", \"standard_charge|max\",\n    \"payer_name\", \"plan_name\", \"billing_class\", \"setting\", \"currency\",\n}",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "FORCE_GZIP",
        "kind": 5,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "FORCE_GZIP = True  # True -> write .csv.gz\n# Pricing/structure headers we expect in a REAL header row\nEXPECTED_TOKENS = {\n    \"description\", \"code|\", \"code|1\", \"code|1|type\", \"code|2\", \"code|2|type\",\n    \"standard_charge\", \"standard_charge|gross\", \"standard_charge|discounted_cash\",\n    \"standard_charge|negotiated_dollar\", \"standard_charge|negotiated_percentage\",\n    \"standard_charge|min\", \"standard_charge|max\",\n    \"payer_name\", \"plan_name\", \"billing_class\", \"setting\", \"currency\",\n}\n# “Admin-only” tokens that frequently show up in those top 2 rows (metadata)",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "EXPECTED_TOKENS",
        "kind": 5,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "EXPECTED_TOKENS = {\n    \"description\", \"code|\", \"code|1\", \"code|1|type\", \"code|2\", \"code|2|type\",\n    \"standard_charge\", \"standard_charge|gross\", \"standard_charge|discounted_cash\",\n    \"standard_charge|negotiated_dollar\", \"standard_charge|negotiated_percentage\",\n    \"standard_charge|min\", \"standard_charge|max\",\n    \"payer_name\", \"plan_name\", \"billing_class\", \"setting\", \"currency\",\n}\n# “Admin-only” tokens that frequently show up in those top 2 rows (metadata)\nADMIN_HINTS = {\n    \"hospital_name\", \"last_updated_on\", \"hospital_location\", \"hospital_address\",",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "ADMIN_HINTS",
        "kind": 5,
        "importPath": "clean-csv-hospitalData",
        "description": "clean-csv-hospitalData",
        "peekOfCode": "ADMIN_HINTS = {\n    \"hospital_name\", \"last_updated_on\", \"hospital_location\", \"hospital_address\",\n    \"license_number|\", \"license_number|wa\", \"version\",\n    \"to the best of its knowledge\",  # attestation text\n    \"45 cfr 180.50\", \"attestation\", \"standard charge information\"\n}\n# ============================================\ndef open_text(path):\n    if path.lower().endswith(\".gz\"):\n        return gzip.open(path, \"rt\", errors=\"replace\", encoding=\"utf-8\")",
        "detail": "clean-csv-hospitalData",
        "documentation": {}
    },
    {
        "label": "norm_key",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def norm_key(s: str) -> str:\n    # normalize a header to a canonical key: lowercase, collapse spaces/punct to \"_\"\n    return NORM_RE.sub(\"_\", str(s).strip().lower()).strip(\"_\")\n# synonyms for meta fields (keys are canonical output names)\nMETA_SYNONYMS = {\n    \"hospital_name\": {\"hospital_name\",\"facility_name\",\"provider_name\",\"hospital\",\"facility\"},\n    \"hospital_location\": {\"hospital_location\",\"location\",\"address_city_state_zip\",\"city_state_zip\",\"city_state_zip_code\"},\n    \"hospital_address\": {\"hospital_address\",\"address\",\"street\",\"street_address\",\"address_line_1\",\"address_1\"},\n    \"last_updated_on\": {\"last_updated_on\",\"last_updated\",\"updated_on\",\"update_date\",\"date\"},\n    \"version\": {\"version\",\"schema_version\",\"file_version\"},",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "read_csv_with_fallback",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def read_csv_with_fallback(path, **kwargs):\n    last_err = None\n    for enc in ENCODING_TRY:\n        try:\n            return pd.read_csv(path, encoding=enc, **kwargs), enc\n        except UnicodeDecodeError as e:\n            last_err = e\n            continue\n    raise last_err\nSENTINEL_NULLS = {",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "clean_amount_like",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def clean_amount_like(v):\n    if v is None:\n        return None\n    s = str(v).strip()\n    if s == \"\":\n        return None\n    sl = s.lower()\n    if sl in SENTINEL_NULLS:\n        return None\n    # strip currency formatting",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "normalize_str",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def normalize_str(x):\n    if isinstance(x, str):\n        return x.replace(\"\\xa0\", \" \").strip()\n    return x\ndef sniff_delimiter(path, default=\",\", sample_lines=6):\n    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        head = [next(f, \"\") for _ in range(sample_lines)]\n    if not head:\n        return default\n    header_raw = head[min(2, len(head)-1)]",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "sniff_delimiter",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def sniff_delimiter(path, default=\",\", sample_lines=6):\n    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        head = [next(f, \"\") for _ in range(sample_lines)]\n    if not head:\n        return default\n    header_raw = head[min(2, len(head)-1)]\n    contains_scg = \"standard_charge|gross\" in header_raw\n    best = default\n    best_score = (-1, -10**9)  # (median_cols, -variance)\n    for d in CANDIDATE_DELIMS:  # CANDIDATE_DELIMS = [\",\", \"\\t\", \";\"]",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "find_true_header_row",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def find_true_header_row(path, delim, max_scan=10):\n    \"\"\"\n    Return 0-based index of the real header line.\n    Heuristic: look for a line that contains 'description' and multiple 'code' columns.\n    \"\"\"\n    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for i in range(max_scan):\n            line = f.readline()\n            if not line:\n                break",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "iter_chunks_with_encoding_fallback",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def iter_chunks_with_encoding_fallback(path, hdr_idx, delim, chunksize):\n    for enc in ENCODING_TRY:\n        try:\n            it = pd.read_csv(\n                path, skiprows=hdr_idx, header=0, dtype=str, sep=delim, engine=\"c\",\n                chunksize=chunksize, on_bad_lines=\"skip\", encoding=enc\n            )\n            for ch in it:\n                yield ch\n            return  # finished fine with this encoding",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def parse_args():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data-dir\", required=True, help=\"Folder containing *.csv files\")\n    ap.add_argument(\"--pg\", default=DEFAULT_PG_DSN, help=\"Postgres connection string\")\n    ap.add_argument(\"--schema\", default=\"hp\")\n    ap.add_argument(\"--table\", default=\"charge_long\")\n    ap.add_argument(\"--delimiter\", default=\",\", help=\"CSV delimiter (default ,)\")\n    ap.add_argument(\"--encoding\", default=\"utf-8\")\n    return ap.parse_args()\ndef clean_name(s):",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "clean_name",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def clean_name(s):\n    if s is None:\n        return None\n    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n# Column synonyms (all compared on norm_key)\nPAYER_COLS = {\"payer_name\",\"payer\",\"insurance\",\"insurance_name\",\"company\",\"insurer\",\"carrier\",\"health_plan\",\"health_insurance\"}\nPLAN_COLS  = {\"plan_name\",\"plan\",\"product\",\"line_of_business\",\"lob\",\"network\",\"tier\",\"coverage\",\"insurance_type\"}\nNEGOTIATED_DOLLAR_COLS = {\n    \"negotiated_dollar\",\"negotiated_rate\",\"allowed_amount\",\"contracted_rate\",\n    \"standard_charge\",\"price\",\"rate\",\"payer_specific_price\"",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "yield_tall_rows",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),\n    yield dict rows ready for COPY into hp.charge_long.\n    Supports two shapes:\n      1) Wide (payer/plan encoded in column names like 'standard_charge|Aetna|Commercial|negotiated_dollar')\n      2) Row-wise (explicit columns like 'payer_name', 'plan_name', 'Standard_Charge', 'Estimated_Amount', etc.)\n    \"\"\"\n    # Normalize column names to strings (preserve original casing, but prepare helpers)\n    orig_cols = list(chunk.columns)",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "copy_rows",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def copy_rows(conn, schema, table, rows, columns):\n    \"\"\"\n    COPY rows to Postgres using CSV format (robust against commas, tabs, quotes).\n    \"\"\"\n    import csv\n    from io import StringIO\n    def quote_ident(name: str) -> str:\n        return '\"' + str(name).replace('\"', '\"\"') + '\"'\n    buf = StringIO()\n    # Use double-quoting for quotes; DO NOT set escapechar equal to quotechar",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "def main():\n    args = parse_args()\n    files = sorted(glob(os.path.join(args.data_dir, \"*.csv\")))\n    if not files:\n        print(\"No CSV files found.\", file=sys.stderr)\n        sys.exit(1)\n    target_cols = [\n        \"file_name\",\n        \"hospital_name\", \"hospital_location\", \"hospital_address\", \"license_number|CA\",\n        \"last_updated_on\", \"version\",",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "ENCODING_TRY",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "ENCODING_TRY = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\nCANDIDATE_DELIMS = [\",\", \"\\t\", \";\"]\nNORM_RE = re.compile(r\"[^a-z0-9|]+\")  # keep letters, digits, and the pipe\ndef norm_key(s: str) -> str:\n    # normalize a header to a canonical key: lowercase, collapse spaces/punct to \"_\"\n    return NORM_RE.sub(\"_\", str(s).strip().lower()).strip(\"_\")\n# synonyms for meta fields (keys are canonical output names)\nMETA_SYNONYMS = {\n    \"hospital_name\": {\"hospital_name\",\"facility_name\",\"provider_name\",\"hospital\",\"facility\"},\n    \"hospital_location\": {\"hospital_location\",\"location\",\"address_city_state_zip\",\"city_state_zip\",\"city_state_zip_code\"},",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "CANDIDATE_DELIMS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "CANDIDATE_DELIMS = [\",\", \"\\t\", \";\"]\nNORM_RE = re.compile(r\"[^a-z0-9|]+\")  # keep letters, digits, and the pipe\ndef norm_key(s: str) -> str:\n    # normalize a header to a canonical key: lowercase, collapse spaces/punct to \"_\"\n    return NORM_RE.sub(\"_\", str(s).strip().lower()).strip(\"_\")\n# synonyms for meta fields (keys are canonical output names)\nMETA_SYNONYMS = {\n    \"hospital_name\": {\"hospital_name\",\"facility_name\",\"provider_name\",\"hospital\",\"facility\"},\n    \"hospital_location\": {\"hospital_location\",\"location\",\"address_city_state_zip\",\"city_state_zip\",\"city_state_zip_code\"},\n    \"hospital_address\": {\"hospital_address\",\"address\",\"street\",\"street_address\",\"address_line_1\",\"address_1\"},",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "NORM_RE",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "NORM_RE = re.compile(r\"[^a-z0-9|]+\")  # keep letters, digits, and the pipe\ndef norm_key(s: str) -> str:\n    # normalize a header to a canonical key: lowercase, collapse spaces/punct to \"_\"\n    return NORM_RE.sub(\"_\", str(s).strip().lower()).strip(\"_\")\n# synonyms for meta fields (keys are canonical output names)\nMETA_SYNONYMS = {\n    \"hospital_name\": {\"hospital_name\",\"facility_name\",\"provider_name\",\"hospital\",\"facility\"},\n    \"hospital_location\": {\"hospital_location\",\"location\",\"address_city_state_zip\",\"city_state_zip\",\"city_state_zip_code\"},\n    \"hospital_address\": {\"hospital_address\",\"address\",\"street\",\"street_address\",\"address_line_1\",\"address_1\"},\n    \"last_updated_on\": {\"last_updated_on\",\"last_updated\",\"updated_on\",\"update_date\",\"date\"},",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "META_SYNONYMS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "META_SYNONYMS = {\n    \"hospital_name\": {\"hospital_name\",\"facility_name\",\"provider_name\",\"hospital\",\"facility\"},\n    \"hospital_location\": {\"hospital_location\",\"location\",\"address_city_state_zip\",\"city_state_zip\",\"city_state_zip_code\"},\n    \"hospital_address\": {\"hospital_address\",\"address\",\"street\",\"street_address\",\"address_line_1\",\"address_1\"},\n    \"last_updated_on\": {\"last_updated_on\",\"last_updated\",\"updated_on\",\"update_date\",\"date\"},\n    \"version\": {\"version\",\"schema_version\",\"file_version\"},\n    # license: accept many forms; we’ll store in license_number|CA as requested\n    \"license_number|ca\": {\n        \"license_number|ca\",\"license_number\",\"facility_license_number\",\"hospital_license_number\",\n        \"license_no\",\"state_license_number\",\"license\",\"license_number|wa\"",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "SENTINEL_NULLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "SENTINEL_NULLS = {\n    \"na\",\"n/a\",\"none\",\"null\",\"nan\",\"not disclosed\",\"not_disclosed\",\"not available\",\"n.a.\"\n}\nSENTINEL_BIG = {\"999999999\", \"999999999.0\", \"999999999.00\"}\ndef clean_amount_like(v):\n    if v is None:\n        return None\n    s = str(v).strip()\n    if s == \"\":\n        return None",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "SENTINEL_BIG",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "SENTINEL_BIG = {\"999999999\", \"999999999.0\", \"999999999.00\"}\ndef clean_amount_like(v):\n    if v is None:\n        return None\n    s = str(v).strip()\n    if s == \"\":\n        return None\n    sl = s.lower()\n    if sl in SENTINEL_NULLS:\n        return None",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "WIDE_BASE_COLS_ORDER",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "WIDE_BASE_COLS_ORDER = [\n    \"description\",\n    \"code\",\n    \"code|1\", \"code|1|type\",\n    \"code|2\", \"code|2|type\",\n    \"code|3\", \"code|3|type\",\n    \"code|4\", \"code|4|type\",\n    \"code|5\", \"code|5|type\",\n    \"code|6\", \"code|6|type\",\n    \"modifiers\",",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "PAYER_METRIC_PREFIXES",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "PAYER_METRIC_PREFIXES = (\n    \"standard_charge|\", \"estimated_amount|\", \"additional_payer_notes|\", \"methodology|\"\n)\nNEGOTIATED_METRICS = {\"negotiated_dollar\", \"negotiated_percentage\", \"negotiated_algorithm\"}\n# Some columns show min/max; we ignore those for the tall row but you can add if needed.\nIGNORE_STANDARD_CHARGE_SUFFIXES = {\"min\", \"max\"}\nCHUNKSIZE = 75_000  # adjust if you hit memory limits\n# ----------------------------\ndef parse_args():\n    ap = argparse.ArgumentParser()",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "NEGOTIATED_METRICS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "NEGOTIATED_METRICS = {\"negotiated_dollar\", \"negotiated_percentage\", \"negotiated_algorithm\"}\n# Some columns show min/max; we ignore those for the tall row but you can add if needed.\nIGNORE_STANDARD_CHARGE_SUFFIXES = {\"min\", \"max\"}\nCHUNKSIZE = 75_000  # adjust if you hit memory limits\n# ----------------------------\ndef parse_args():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data-dir\", required=True, help=\"Folder containing *.csv files\")\n    ap.add_argument(\"--pg\", default=DEFAULT_PG_DSN, help=\"Postgres connection string\")\n    ap.add_argument(\"--schema\", default=\"hp\")",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "IGNORE_STANDARD_CHARGE_SUFFIXES",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "IGNORE_STANDARD_CHARGE_SUFFIXES = {\"min\", \"max\"}\nCHUNKSIZE = 75_000  # adjust if you hit memory limits\n# ----------------------------\ndef parse_args():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data-dir\", required=True, help=\"Folder containing *.csv files\")\n    ap.add_argument(\"--pg\", default=DEFAULT_PG_DSN, help=\"Postgres connection string\")\n    ap.add_argument(\"--schema\", default=\"hp\")\n    ap.add_argument(\"--table\", default=\"charge_long\")\n    ap.add_argument(\"--delimiter\", default=\",\", help=\"CSV delimiter (default ,)\")",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "CHUNKSIZE",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "CHUNKSIZE = 75_000  # adjust if you hit memory limits\n# ----------------------------\ndef parse_args():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data-dir\", required=True, help=\"Folder containing *.csv files\")\n    ap.add_argument(\"--pg\", default=DEFAULT_PG_DSN, help=\"Postgres connection string\")\n    ap.add_argument(\"--schema\", default=\"hp\")\n    ap.add_argument(\"--table\", default=\"charge_long\")\n    ap.add_argument(\"--delimiter\", default=\",\", help=\"CSV delimiter (default ,)\")\n    ap.add_argument(\"--encoding\", default=\"utf-8\")",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "PAYER_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "PAYER_COLS = {\"payer_name\",\"payer\",\"insurance\",\"insurance_name\",\"company\",\"insurer\",\"carrier\",\"health_plan\",\"health_insurance\"}\nPLAN_COLS  = {\"plan_name\",\"plan\",\"product\",\"line_of_business\",\"lob\",\"network\",\"tier\",\"coverage\",\"insurance_type\"}\nNEGOTIATED_DOLLAR_COLS = {\n    \"negotiated_dollar\",\"negotiated_rate\",\"allowed_amount\",\"contracted_rate\",\n    \"standard_charge\",\"price\",\"rate\",\"payer_specific_price\"\n}\nNEGOTIATED_PCT_COLS = {\n    \"negotiated_percentage\",\"percent_of_charges\",\"discount_percentage\",\"pct_of_charges\",\"percentage\"\n}\nALGO_COLS = {\"negotiated_algorithm\",\"algorithm\",\"pricing_algorithm\"}",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "NEGOTIATED_DOLLAR_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "NEGOTIATED_DOLLAR_COLS = {\n    \"negotiated_dollar\",\"negotiated_rate\",\"allowed_amount\",\"contracted_rate\",\n    \"standard_charge\",\"price\",\"rate\",\"payer_specific_price\"\n}\nNEGOTIATED_PCT_COLS = {\n    \"negotiated_percentage\",\"percent_of_charges\",\"discount_percentage\",\"pct_of_charges\",\"percentage\"\n}\nALGO_COLS = {\"negotiated_algorithm\",\"algorithm\",\"pricing_algorithm\"}\nESTIMATE_COLS = {\"estimated_amount\",\"estimate\",\"estimated_price\",\"est_amount\"}\nMETHODOLOGY_COLS = {\"methodology\",\"pricing_methodology\",\"calc_method\"}",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "NEGOTIATED_PCT_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "NEGOTIATED_PCT_COLS = {\n    \"negotiated_percentage\",\"percent_of_charges\",\"discount_percentage\",\"pct_of_charges\",\"percentage\"\n}\nALGO_COLS = {\"negotiated_algorithm\",\"algorithm\",\"pricing_algorithm\"}\nESTIMATE_COLS = {\"estimated_amount\",\"estimate\",\"estimated_price\",\"est_amount\"}\nMETHODOLOGY_COLS = {\"methodology\",\"pricing_methodology\",\"calc_method\"}\nNOTES_COLS = {\"additional_payer_notes\",\"payer_notes\",\"notes\",\"remark\",\"comments\",\"additional_notes\"}\ndef yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "ALGO_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "ALGO_COLS = {\"negotiated_algorithm\",\"algorithm\",\"pricing_algorithm\"}\nESTIMATE_COLS = {\"estimated_amount\",\"estimate\",\"estimated_price\",\"est_amount\"}\nMETHODOLOGY_COLS = {\"methodology\",\"pricing_methodology\",\"calc_method\"}\nNOTES_COLS = {\"additional_payer_notes\",\"payer_notes\",\"notes\",\"remark\",\"comments\",\"additional_notes\"}\ndef yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),\n    yield dict rows ready for COPY into hp.charge_long.\n    Supports two shapes:\n      1) Wide (payer/plan encoded in column names like 'standard_charge|Aetna|Commercial|negotiated_dollar')",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "ESTIMATE_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "ESTIMATE_COLS = {\"estimated_amount\",\"estimate\",\"estimated_price\",\"est_amount\"}\nMETHODOLOGY_COLS = {\"methodology\",\"pricing_methodology\",\"calc_method\"}\nNOTES_COLS = {\"additional_payer_notes\",\"payer_notes\",\"notes\",\"remark\",\"comments\",\"additional_notes\"}\ndef yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),\n    yield dict rows ready for COPY into hp.charge_long.\n    Supports two shapes:\n      1) Wide (payer/plan encoded in column names like 'standard_charge|Aetna|Commercial|negotiated_dollar')\n      2) Row-wise (explicit columns like 'payer_name', 'plan_name', 'Standard_Charge', 'Estimated_Amount', etc.)",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "METHODOLOGY_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "METHODOLOGY_COLS = {\"methodology\",\"pricing_methodology\",\"calc_method\"}\nNOTES_COLS = {\"additional_payer_notes\",\"payer_notes\",\"notes\",\"remark\",\"comments\",\"additional_notes\"}\ndef yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),\n    yield dict rows ready for COPY into hp.charge_long.\n    Supports two shapes:\n      1) Wide (payer/plan encoded in column names like 'standard_charge|Aetna|Commercial|negotiated_dollar')\n      2) Row-wise (explicit columns like 'payer_name', 'plan_name', 'Standard_Charge', 'Estimated_Amount', etc.)\n    \"\"\"",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "NOTES_COLS",
        "kind": 5,
        "importPath": "hp_long_loader",
        "description": "hp_long_loader",
        "peekOfCode": "NOTES_COLS = {\"additional_payer_notes\",\"payer_notes\",\"notes\",\"remark\",\"comments\",\"additional_notes\"}\ndef yield_tall_rows(meta, chunk):\n    \"\"\"\n    Given hospital meta (dict) and a wide chunk (DataFrame),\n    yield dict rows ready for COPY into hp.charge_long.\n    Supports two shapes:\n      1) Wide (payer/plan encoded in column names like 'standard_charge|Aetna|Commercial|negotiated_dollar')\n      2) Row-wise (explicit columns like 'payer_name', 'plan_name', 'Standard_Charge', 'Estimated_Amount', etc.)\n    \"\"\"\n    # Normalize column names to strings (preserve original casing, but prepare helpers)",
        "detail": "hp_long_loader",
        "documentation": {}
    },
    {
        "label": "open_any",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def open_any(path: str):\n    \"\"\"Open text or gzipped CSV as text, letting pandas handle encoding.\"\"\"\n    return gzip.open(path, \"rt\", errors=\"replace\") if path.endswith(\".gz\") else open(path, \"r\", errors=\"replace\")\ndef _try_read(path: str, encoding: str, sep, engine: str):\n    df = pd.read_csv(\n        open_any(path),\n        dtype=str,\n        encoding=encoding,\n        sep=sep,                 \n        engine=engine,           ",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "read_csv_any",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def read_csv_any(path: str) -> pd.DataFrame:\n    \"\"\"Robust CSV reader trying common encodings and delimiters.\"\"\"\n    for encoding in (\"utf-8\", \"latin-1\"):\n        for sep in (None, \",\", \"\\t\", \"|\", \";\"):\n            try:\n                df = _try_read(path, encoding=encoding, sep=sep, engine=\"python\")\n                print(f\"   ✓ Parsed with encoding={encoding} sep={'auto' if sep is None else sep}\")\n                return df\n            except Exception:\n                continue",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "normalize_header",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def normalize_header(col: str) -> str:\n    c = str(col).strip().lower()\n    c = c.replace(\"-\", \"_\")             # dashes → underscores\n    c = re.sub(r\"\\s*\\|\\s*\", \"|\", c)     # \" a | b \" → \"a|b\"\n    c = re.sub(r\"\\s+\", \" \", c)          # collapse spaces\n    return c\ndef is_charge_col(col: str) -> bool:\n    \"\"\"\n    Accept many real-world variants:\n      - standard_charge|gross, standard charge|gross, standard_charge (no suffix)",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "is_charge_col",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def is_charge_col(col: str) -> bool:\n    \"\"\"\n    Accept many real-world variants:\n      - standard_charge|gross, standard charge|gross, standard_charge (no suffix)\n      - standard_charge|discounted_cash|min|max\n      - bare names: gross_charge, chargemaster, discounted_cash, negotiated_dollar, negotiated_percentage, min, max\n    \"\"\"\n    c = normalize_header(col)\n    if c in (\"standard_charge\", \"standard charge\"):\n        return True",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "col_to_price_type_from_name",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def col_to_price_type_from_name(col: str) -> str:\n    \"\"\"Map a (possibly deduped) charge column name to canonical price_type.\"\"\"\n    b = col.split(\"__\", 1)[0]  # strip any __N suffix\n    # extract suffix after \"standard_charge|\"\n    if \"|\" in b:\n        suffix = b.split(\"|\", 1)[1]\n    else:\n        bare = b.replace(\" \", \"_\")\n        if bare in (\"gross\", \"gross_charge\", \"gross_charges\", \"chargemaster\", \"standard_charge\"):\n            suffix = \"gross\"",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "col_or_blank",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def col_or_blank(df, col):\n    \"\"\"Return df[col] if it exists, else a same-length Series of empty strings.\"\"\"\n    if col in df.columns:\n        return df[col].fillna(\"\")\n    else:\n        return pd.Series([\"\"] * len(df), index=df.index)\ndef _make_unique(names):\n    seen = {}\n    out = []\n    for n in names:",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "melt_and_normalize",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def melt_and_normalize(df: pd.DataFrame, hospital_name: str) -> pd.DataFrame:\n    # 0) normalize and dedupe headers\n    df = df.copy()\n    df.columns = [normalize_header(c) for c in df.columns]\n    if len(set(df.columns)) != len(df.columns):\n        df.columns = _make_unique(df.columns)\n        print(\"   ↳ detected duplicate headers; made them unique.\")\n    cols = list(df.columns)\n    # helper: first existing column whose base-name matches any candidate\n    def pick_first(*candidates):",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "copy_to_single_table",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def copy_to_single_table(df, source_file):\n    cols = [\n        \"hospital_name\",\"code\",\"code_type\",\"price_type\",\"price_amount\",\n        \"payer_name\",  \"plan_name\", \"billing_class\",\"currency\",\"effective_date\",\"expires_on\",\n        \"description\",\"notes\"\n    ]\n    for c in cols:\n        if c not in df.columns:\n            df[c] = \"\"\n    df = df.copy()",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "def main():\n    files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.csv\")) + glob.glob(os.path.join(DATA_DIR, \"*.csv.gz\")))\n    if not files:\n        print(\"No files found in\", DATA_DIR)\n        return\n    for path in files:\n        hosp = input(f\"Hospital name for {os.path.basename(path)}: \").strip()\n        print(f\"--> Processing {os.path.basename(path)} for hospital={hosp}\")\n        df = read_csv_any(path)\n        tidy = melt_and_normalize(df, hospital_name=hosp)",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "DATA_DIR",
        "kind": 5,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "DATA_DIR = \"/Users/jdd48774/Downloads/out-tall\" ## path for files to load\nENGINE   = create_engine(DB_URL, future=True)\n# Map charge suffix -> canonical price_type\nPRICE_TYPE_MAP = {\n    \"gross\": \"chargemaster\",\n    \"gross_charge\": \"chargemaster\",\n    \"gross_charges\": \"chargemaster\",\n    \"discounted_cash\": \"cash\",\n    \"negotiated_dollar\": \"negotiated\",\n    \"negotiated_percentage\": \"percentage\",",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "PRICE_TYPE_MAP",
        "kind": 5,
        "importPath": "load-csv-database",
        "description": "load-csv-database",
        "peekOfCode": "PRICE_TYPE_MAP = {\n    \"gross\": \"chargemaster\",\n    \"gross_charge\": \"chargemaster\",\n    \"gross_charges\": \"chargemaster\",\n    \"discounted_cash\": \"cash\",\n    \"negotiated_dollar\": \"negotiated\",\n    \"negotiated_percentage\": \"percentage\",\n    \"min\": \"min\",\n    \"max\": \"max\",\n}",
        "detail": "load-csv-database",
        "documentation": {}
    },
    {
        "label": "open_any",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def open_any(path: str):\n    return gzip.open(path, \"rt\", errors=\"replace\") if path.endswith(\".gz\") else open(path, \"r\", errors=\"replace\")\ndef _try_read(path: str, encoding: str, sep, engine: str):\n    return pd.read_csv(\n        open_any(path),\n        dtype=str,\n        encoding=encoding,\n        sep=sep,                 # None => auto (engine='python')\n        engine=engine,           # 'python' parser is more forgiving\n        quotechar='\"',",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "read_csv_any",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def read_csv_any(path: str) -> pd.DataFrame:\n    for enc in (\"utf-8\", \"latin-1\"):\n        for sep in (None, \",\", \"\\t\", \"|\", \";\"):\n            try:\n                df = _try_read(path, enc, sep, \"python\")\n                print(f\"   ✓ Parsed {os.path.basename(path)} with encoding={enc} sep={'auto' if sep is None else sep}\")\n                return df\n            except Exception:\n                continue\n    raise RuntimeError(f\"Unable to parse {os.path.basename(path)} with common encodings/delimiters.\")",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "normalize_header",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def normalize_header(col: str) -> str:\n    c = str(col).strip().lower()\n    c = c.replace(\"-\", \"_\")              # dashes → underscores\n    c = re.sub(r\"\\s*\\|\\s*\", \"|\", c)      # \" a | b \" → \"a|b\"\n    c = re.sub(r\"\\s+\", \" \", c)           # collapse spaces\n    return c\ndef make_unique(cols):\n    seen = {}\n    out = []\n    for n in cols:",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "make_unique",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def make_unique(cols):\n    seen = {}\n    out = []\n    for n in cols:\n        if n not in seen:\n            seen[n] = 0\n            out.append(n)\n        else:\n            seen[n] += 1\n            out.append(f\"{n}__{seen[n]}\")",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "base_name",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def base_name(name: str) -> str:\n    return name.split(\"__\", 1)[0]\n# -------- hospital name from filename --------\nSEP = r\"[_\\- ]\"   # underscore, hyphen, space (hyphen escaped)\n_BOILER = [\n    rf\"standard{SEP}?charges?\", rf\"machine{SEP}?readable\",\n    r\"(?:price|prices?)\", r\"chargemaster\", r\"cdm\",\n    r\"inpatient\", r\"outpatient\", r\"shoppable\"\n]\ndef guess_hospital_name_from_filename(path: str) -> str:",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "guess_hospital_name_from_filename",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def guess_hospital_name_from_filename(path: str) -> str:\n    base = os.path.basename(path)\n    base = re.sub(r\"\\.csv(\\.gz)?$\", \"\", base, flags=re.IGNORECASE)\n    s = base.replace(\"_\", \" \").replace(\"-\", \" \")\n    s = re.sub(r\"^[0-9]{2}-[0-9]{7}\\s+\", \"\", s)  # EIN like 91-0750229\n    s = re.sub(r\"^[0-9]{8}\\s+\", \"\", s)           # YYYYMMDD\n    s = re.sub(r\"^[0-9]{9}\\s+\", \"\", s)           # 9-digit id\n    s = re.sub(r\"^[0-9]+\\s+\", \"\", s)             # any leading number\n    for pat in _BOILER:\n        s = re.sub(rf\"\\b{pat}\\b\", \" \", s, flags=re.IGNORECASE)",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "parse_price_header",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def parse_price_header(colname: str):\n    c = base_name(normalize_header(colname))  # strip __N\n    ptype = None\n    payer = None\n    plan  = None\n    # canonical \"standard_charge|suffix\"\n    if c.startswith(\"standard_charge|\") or c.startswith(\"standard charge|\"):\n        suffix = c.split(\"|\", 1)[1]\n        ptype = PRICE_TYPE_MAP.get(suffix, None)\n    # bare standard_charge",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "detect_wide_price_columns",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def detect_wide_price_columns(cols):\n    out = []\n    for c in cols:\n        ptype, payer, plan = parse_price_header(c)\n        if ptype:\n            out.append((c, ptype, payer, plan))\n    return out\n# ---------- transform to tall ------------\nDESC_ALIASES = [\n    \"description\",\"service_description\",\"procedure_description\",\"item_description\",",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "first_existing",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def first_existing(cols, names):\n    cand = set(names)\n    for n in cols:\n        if base_name(n) in cand:\n            return n\n    return None\ndef coalesce_first(row, candidates):\n    for c in candidates:\n        v = row.get(c, \"\")\n        if isinstance(v, str) and v.strip():",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "coalesce_first",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def coalesce_first(row, candidates):\n    for c in candidates:\n        v = row.get(c, \"\")\n        if isinstance(v, str) and v.strip():\n            return v.strip()\n    for c in candidates:\n        v = row.get(c, \"\")\n        if pd.notna(v) and str(v).strip():\n            return str(v).strip()\n    return \"\"",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "maybe_top_metadata",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def maybe_top_metadata(df: pd.DataFrame) -> tuple[pd.DataFrame, str]:\n    \"\"\"\n    If the first two rows look like a metadata banner (long text / not real headers),\n    capture them into a JSON string and drop them. Otherwise return df, \"\".\n    \"\"\"\n    if df.empty: return df, \"\"\n    # Heuristic: if the *values* of first row contain a very long sentence,\n    # or expected headers are NOT present but the first two rows have lots of long cells.\n    head = list(df.columns)\n    norm = [normalize_header(x) for x in head]",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "to_tall",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def to_tall(df: pd.DataFrame, hospital_name: str) -> pd.DataFrame:\n    # 1) normalize & unique headers\n    df = df.copy()\n    df.columns = [normalize_header(c) for c in df.columns]\n    if len(set(df.columns)) != len(df.columns):\n        df.columns = make_unique(df.columns)\n    # 2) drop metadata top rows if present, capture JSON metadata\n    df, metadata_json = maybe_top_metadata(df)\n    cols = list(df.columns)\n    # 3) pick id columns (keep plan_name separate)",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "def main():\n    os.makedirs(OUT_DIR, exist_ok=True)\n    files = sorted(glob.glob(os.path.join(IN_DIR, \"*.csv\")) + glob.glob(os.path.join(IN_DIR, \"*.csv.gz\")))\n    if not files:\n        print(f\"No files found in {IN_DIR}\")\n        return\n    for path in files:\n        hosp = guess_hospital_name_from_filename(path)\n        out_name = os.path.basename(re.sub(r\"\\.csv(\\.gz)?$\", \"\", path, flags=re.IGNORECASE)) + \".tall.csv\"\n        out_path = os.path.join(OUT_DIR, out_name)",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "OUT_DIR",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "OUT_DIR = \"/Users/jdd48774/Downloads/out-tall\"     # <-- set output folder\nOVERWRITE = True                  # overwrite existing tall files\n# ------------ Helpers: IO --------------\ndef open_any(path: str):\n    return gzip.open(path, \"rt\", errors=\"replace\") if path.endswith(\".gz\") else open(path, \"r\", errors=\"replace\")\ndef _try_read(path: str, encoding: str, sep, engine: str):\n    return pd.read_csv(\n        open_any(path),\n        dtype=str,\n        encoding=encoding,",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "OVERWRITE",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "OVERWRITE = True                  # overwrite existing tall files\n# ------------ Helpers: IO --------------\ndef open_any(path: str):\n    return gzip.open(path, \"rt\", errors=\"replace\") if path.endswith(\".gz\") else open(path, \"r\", errors=\"replace\")\ndef _try_read(path: str, encoding: str, sep, engine: str):\n    return pd.read_csv(\n        open_any(path),\n        dtype=str,\n        encoding=encoding,\n        sep=sep,                 # None => auto (engine='python')",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "SEP",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "SEP = r\"[_\\- ]\"   # underscore, hyphen, space (hyphen escaped)\n_BOILER = [\n    rf\"standard{SEP}?charges?\", rf\"machine{SEP}?readable\",\n    r\"(?:price|prices?)\", r\"chargemaster\", r\"cdm\",\n    r\"inpatient\", r\"outpatient\", r\"shoppable\"\n]\ndef guess_hospital_name_from_filename(path: str) -> str:\n    base = os.path.basename(path)\n    base = re.sub(r\"\\.csv(\\.gz)?$\", \"\", base, flags=re.IGNORECASE)\n    s = base.replace(\"_\", \" \").replace(\"-\", \" \")",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "_BOILER",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "_BOILER = [\n    rf\"standard{SEP}?charges?\", rf\"machine{SEP}?readable\",\n    r\"(?:price|prices?)\", r\"chargemaster\", r\"cdm\",\n    r\"inpatient\", r\"outpatient\", r\"shoppable\"\n]\ndef guess_hospital_name_from_filename(path: str) -> str:\n    base = os.path.basename(path)\n    base = re.sub(r\"\\.csv(\\.gz)?$\", \"\", base, flags=re.IGNORECASE)\n    s = base.replace(\"_\", \" \").replace(\"-\", \" \")\n    s = re.sub(r\"^[0-9]{2}-[0-9]{7}\\s+\", \"\", s)  # EIN like 91-0750229",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "PRICE_TYPE_MAP",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "PRICE_TYPE_MAP = {\n    \"gross\": \"chargemaster\",\n    \"gross_charge\": \"chargemaster\",\n    \"gross_charges\": \"chargemaster\",\n    \"discounted_cash\": \"cash\",\n    \"cash\": \"cash\",\n    \"negotiated_dollar\": \"negotiated\",\n    \"negotiated_rate\": \"negotiated\",\n    \"payer_specific\": \"negotiated\",\n    \"contracted_rate\": \"negotiated\",",
        "detail": "wide-to-tall",
        "documentation": {}
    },
    {
        "label": "DESC_ALIASES",
        "kind": 5,
        "importPath": "wide-to-tall",
        "description": "wide-to-tall",
        "peekOfCode": "DESC_ALIASES = [\n    \"description\",\"service_description\",\"procedure_description\",\"item_description\",\n    \"long_description\",\"short_description\",\"charge_description\",\n    \"standard_charge_description\",\"display_description\",\"name\",\"label\"\n]\ndef first_existing(cols, names):\n    cand = set(names)\n    for n in cols:\n        if base_name(n) in cand:\n            return n",
        "detail": "wide-to-tall",
        "documentation": {}
    }
]